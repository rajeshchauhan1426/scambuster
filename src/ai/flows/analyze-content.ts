
// This is an autogenerated file from Firebase Studio.

'use server';

/**
 * @fileOverview AI-driven tool that analyzes web content to detect potential scams, fraud attempts, and deepfakes.
 *
 * - analyzeContent - A function that analyzes content for scams, fraud, or deepfakes.
 * - AnalyzeContentInput - The input type for the analyzeContent function.
 * - AnalyzeContentOutput - The return type for the analyzeContent function.
 */

import {ai} from '@/ai/genkit';
import {z} from 'genkit';

const AnalyzeContentInputSchema = z.object({
  content: z.string().describe('The website text content to be analyzed.'),
});
export type AnalyzeContentInput = z.infer<typeof AnalyzeContentInputSchema>;

const AnalyzeContentOutputSchema = z.object({
  riskAssessment: z.object({
    isRisky: z.boolean().describe('Whether the content is potentially risky.'),
    riskScore: z.number().describe('A score indicating the risk level (0-100).'),
    reason: z.string().describe('The detailed reason for the risk assessment.'),
  }),
  flags: z.array(z.string()).describe('Specific flags raised during the analysis (e.g., phishing, deepfake).'),
});
export type AnalyzeContentOutput = z.infer<typeof AnalyzeContentOutputSchema>;

export async function analyzeContent(input: AnalyzeContentInput): Promise<AnalyzeContentOutput> {
  return analyzeContentFlow(input);
}

const prompt = ai.definePrompt({
  name: 'analyzeContentPrompt',
  input: {schema: AnalyzeContentInputSchema},
  output: {schema: AnalyzeContentOutputSchema},
  prompt: `You are an AI assistant specializing in detecting online scams, fraud, and deepfakes.
  Analyze the following content and provide a risk assessment. Pay special attention to wording and grammar.

Content: {{{content}}}

Consider these factors:
- Phishing attempts
- Fraudulent schemes
- Deepfake indicators
- Suspicious links or requests
- Grammar and wording indicative of fraud

Set the isRisky field appropriately, assigning the riskScore from 0-100, and providing a detailed reason for the assessment.
Provide specific flags raised during the analysis (e.g., phishing, deepfake). Do not just make up vulnerabilities - they should be grounded in fact. Limit the flags to 3 items.

Output should conform to the AnalyzeContentOutputSchema schema. Focus on providing a very detailed "reason" field.
  `,
});

const analyzeContentFlow = ai.defineFlow(
  {
    name: 'analyzeContentFlow',
    inputSchema: AnalyzeContentInputSchema,
    outputSchema: AnalyzeContentOutputSchema,
  },
  async input => {
    const {output} = await prompt(input);
    return output!;
  }
);
